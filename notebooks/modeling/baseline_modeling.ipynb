{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUFG DataScience Challenge 2025 - Baseline Random Forest Model\n",
    "\n",
    "This notebook creates a baseline Random Forest model for predicting crowdfunding project success with F1 score evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (75690, 13)\n",
      "Test data shape: (32439, 12)\n",
      "\n",
      "Target distribution in training data:\n",
      "final_status\n",
      "0    0.680473\n",
      "1    0.319527\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load training and test data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"\\nTarget distribution in training data:\")\n",
    "print(train_df['final_status'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering completed!\n",
      "New training data shape: (75690, 31)\n"
     ]
    }
   ],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Create engineered features for the dataset\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert timestamps to datetime\n",
    "    timestamp_cols = ['deadline', 'state_changed_at', 'created_at', 'launched_at']\n",
    "    for col in timestamp_cols:\n",
    "        df[f'{col}_dt'] = pd.to_datetime(df[col], unit='s')\n",
    "    \n",
    "    # Create temporal features\n",
    "    df['campaign_duration'] = (df['deadline_dt'] - df['launched_at_dt']).dt.days\n",
    "    df['prep_time'] = (df['launched_at_dt'] - df['created_at_dt']).dt.days\n",
    "    \n",
    "    # Extract date components\n",
    "    df['launch_year'] = df['launched_at_dt'].dt.year\n",
    "    df['launch_month'] = df['launched_at_dt'].dt.month\n",
    "    df['launch_day_of_week'] = df['launched_at_dt'].dt.dayofweek\n",
    "    df['launch_quarter'] = df['launched_at_dt'].dt.quarter\n",
    "    \n",
    "    # Text length features\n",
    "    df['name_length'] = df['name'].str.len()\n",
    "    df['desc_length'] = df['desc'].str.len()\n",
    "    df['keywords_length'] = df['keywords'].str.len()\n",
    "    df['name_word_count'] = df['name'].str.split().str.len()\n",
    "    df['desc_word_count'] = df['desc'].str.split().str.len()\n",
    "    \n",
    "    # Goal amount transformations\n",
    "    df['log_goal'] = np.log1p(df['goal'])\n",
    "    df['goal_per_day'] = df['goal'] / np.maximum(df['campaign_duration'], 1)\n",
    "    \n",
    "    # Communication feature\n",
    "    df['disable_communication_int'] = df['disable_communication'].astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_engineered = engineer_features(train_df)\n",
    "test_engineered = engineer_features(test_df)\n",
    "\n",
    "print(\"Feature engineering completed!\")\n",
    "print(f\"New training data shape: {train_engineered.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: 17\n",
      "Features: ['goal', 'log_goal', 'goal_per_day', 'campaign_duration', 'prep_time', 'launch_year', 'launch_month', 'launch_day_of_week', 'launch_quarter', 'name_length', 'desc_length', 'keywords_length', 'name_word_count', 'desc_word_count', 'disable_communication_int', 'country', 'currency']\n"
     ]
    }
   ],
   "source": [
    "# Select features for modeling\n",
    "feature_cols = [\n",
    "    # Numerical features\n",
    "    'goal', 'log_goal', 'goal_per_day',\n",
    "    'campaign_duration', 'prep_time',\n",
    "    'launch_year', 'launch_month', 'launch_day_of_week', 'launch_quarter',\n",
    "    'name_length', 'desc_length', 'keywords_length',\n",
    "    'name_word_count', 'desc_word_count',\n",
    "    'disable_communication_int',\n",
    "    # Categorical features to encode\n",
    "    'country', 'currency'\n",
    "]\n",
    "\n",
    "# Prepare data for modeling\n",
    "X_train_raw = train_engineered[feature_cols].copy()\n",
    "y_train = train_engineered['final_status'].copy()\n",
    "X_test_raw = test_engineered[feature_cols].copy()\n",
    "\n",
    "print(f\"Selected features: {len(feature_cols)}\")\n",
    "print(f\"Features: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded country: 11 unique values\n",
      "Encoded currency: 9 unique values\n",
      "\n",
      "Final training features shape: (75690, 17)\n",
      "Final test features shape: (32439, 17)\n"
     ]
    }
   ],
   "source": [
    "# Handle categorical encoding\n",
    "categorical_features = ['country', 'currency']\n",
    "label_encoders = {}\n",
    "\n",
    "X_train = X_train_raw.copy()\n",
    "X_test = X_test_raw.copy()\n",
    "\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # Fit on combined data to handle unseen categories\n",
    "    combined_values = pd.concat([X_train[col], X_test[col]]).astype(str)\n",
    "    le.fit(combined_values)\n",
    "    \n",
    "    # Transform both datasets\n",
    "    X_train[col] = le.transform(X_train[col].astype(str))\n",
    "    X_test[col] = le.transform(X_test[col].astype(str))\n",
    "    \n",
    "    label_encoders[col] = le\n",
    "    print(f\"Encoded {col}: {len(le.classes_)} unique values\")\n",
    "\n",
    "# Handle any remaining missing values\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "print(f\"\\nFinal training features shape: {X_train.shape}\")\n",
    "print(f\"Final test features shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (60552, 17)\n",
      "Validation set shape: (15138, 17)\n",
      "\n",
      "Target distribution in training split:\n",
      "final_status\n",
      "0    0.680473\n",
      "1    0.319527\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Target distribution in validation split:\n",
      "final_status\n",
      "0    0.680473\n",
      "1    0.319527\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split training data into train/validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train_split.shape}\")\n",
    "print(f\"Validation set shape: {X_val_split.shape}\")\n",
    "print(f\"\\nTarget distribution in training split:\")\n",
    "print(pd.Series(y_train_split).value_counts(normalize=True))\n",
    "print(f\"\\nTarget distribution in validation split:\")\n",
    "print(pd.Series(y_val_split).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Forest Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest parameters:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Initialize Random Forest with reasonable parameters\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,          # Number of trees\n",
    "    max_depth=15,              # Maximum depth of trees\n",
    "    min_samples_split=10,      # Minimum samples to split\n",
    "    min_samples_leaf=5,        # Minimum samples in leaf\n",
    "    max_features='sqrt',       # Number of features to consider at each split\n",
    "    random_state=42,           # For reproducibility\n",
    "    n_jobs=-1,                 # Use all available cores\n",
    "    class_weight='balanced'    # Handle class imbalance\n",
    ")\n",
    "\n",
    "print(\"Random Forest parameters:\")\n",
    "print(rf_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model.fit(X_train_split, y_train_split)\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation - F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASELINE RANDOM FOREST RESULTS ===\n",
      "\n",
      "F1 Score Results:\n",
      "Training F1 Score: 0.7251\n",
      "Validation F1 Score: 0.5234\n",
      "Overfitting Check: 0.2017 (lower is better)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_train_pred = rf_model.predict(X_train_split)\n",
    "y_val_pred = rf_model.predict(X_val_split)\n",
    "\n",
    "# Calculate F1 scores\n",
    "train_f1 = f1_score(y_train_split, y_train_pred)\n",
    "val_f1 = f1_score(y_val_split, y_val_pred)\n",
    "\n",
    "print(\"=== BASELINE RANDOM FOREST RESULTS ===\")\n",
    "print(f\"\\nF1 Score Results:\")\n",
    "print(f\"Training F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "print(f\"Overfitting Check: {train_f1 - val_f1:.4f} (lower is better)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VALIDATION SET DETAILED RESULTS ===\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.66      0.72     10301\n",
      "           1       0.46      0.61      0.52      4837\n",
      "\n",
      "    accuracy                           0.64     15138\n",
      "   macro avg       0.62      0.64      0.62     15138\n",
      "weighted avg       0.68      0.64      0.65     15138\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6792 3509]\n",
      " [1879 2958]]\n",
      "\n",
      "Confusion Matrix Breakdown:\n",
      "True Negatives (Correctly predicted failures): 6792\n",
      "False Positives (Incorrectly predicted successes): 3509\n",
      "False Negatives (Incorrectly predicted failures): 1879\n",
      "True Positives (Correctly predicted successes): 2958\n"
     ]
    }
   ],
   "source": [
    "# Detailed classification report for validation set\n",
    "print(\"\\n=== VALIDATION SET DETAILED RESULTS ===\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val_split, y_val_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_val_split, y_val_pred)\n",
    "print(cm)\n",
    "print(\"\\nConfusion Matrix Breakdown:\")\n",
    "print(f\"True Negatives (Correctly predicted failures): {cm[0,0]}\")\n",
    "print(f\"False Positives (Incorrectly predicted successes): {cm[0,1]}\")\n",
    "print(f\"False Negatives (Incorrectly predicted failures): {cm[1,0]}\")\n",
    "print(f\"True Positives (Correctly predicted successes): {cm[1,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP 10 MOST IMPORTANT FEATURES ===\n",
      "              feature  importance\n",
      "4           prep_time    0.132005\n",
      "2        goal_per_day    0.097957\n",
      "1            log_goal    0.092254\n",
      "0                goal    0.089533\n",
      "3   campaign_duration    0.081529\n",
      "10        desc_length    0.076999\n",
      "5         launch_year    0.074134\n",
      "9         name_length    0.068796\n",
      "11    keywords_length    0.062604\n",
      "13    desc_word_count    0.058237\n",
      "\n",
      "Top 10 Features (as percentages):\n",
      "prep_time: 13.2%\n",
      "goal_per_day: 9.8%\n",
      "log_goal: 9.23%\n",
      "goal: 8.95%\n",
      "campaign_duration: 8.15%\n",
      "desc_length: 7.7%\n",
      "launch_year: 7.41%\n",
      "name_length: 6.88%\n",
      "keywords_length: 6.26%\n",
      "desc_word_count: 5.82%\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== TOP 10 MOST IMPORTANT FEATURES ===\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Show feature importance as percentages\n",
    "print(\"\\nTop 10 Features (as percentages):\")\n",
    "top10 = feature_importance.head(10).copy()\n",
    "top10['importance_pct'] = (top10['importance'] * 100).round(2)\n",
    "for idx, row in top10.iterrows():\n",
    "    print(f\"{row['feature']}: {row['importance_pct']}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining model on full training dataset...\n",
      "Final model F1 score on full training set: 0.7113\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the full training set (for final model)\n",
    "print(\"Retraining model on full training dataset...\")\n",
    "rf_final = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "rf_final.fit(X_train, y_train)\n",
    "\n",
    "# Final training F1 score\n",
    "y_train_final_pred = rf_final.predict(X_train)\n",
    "train_final_f1 = f1_score(y_train, y_train_final_pred)\n",
    "\n",
    "print(f\"Final model F1 score on full training set: {train_final_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions summary:\n",
      "Total test samples: 32439\n",
      "Predicted successes: 14015 (43.2%)\n",
      "Predicted failures: 18424 (56.8%)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "test_predictions = rf_final.predict(X_test)\n",
    "test_probabilities = rf_final.predict_proba(X_test)[:, 1]  # Get probability of success\n",
    "\n",
    "print(f\"Test predictions summary:\")\n",
    "print(f\"Total test samples: {len(test_predictions)}\")\n",
    "print(f\"Predicted successes: {sum(test_predictions)} ({sum(test_predictions)/len(test_predictions)*100:.1f}%)\")\n",
    "print(f\"Predicted failures: {len(test_predictions) - sum(test_predictions)} ({(len(test_predictions) - sum(test_predictions))/len(test_predictions)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: baseline_rf_submission.csv\n",
      "\n",
      "Submission preview:\n",
      "           id  final_status\n",
      "0  test_00000             1\n",
      "1  test_00001             0\n",
      "2  test_00002             1\n",
      "3  test_00003             0\n",
      "4  test_00004             1\n",
      "5  test_00005             1\n",
      "6  test_00006             1\n",
      "7  test_00007             1\n",
      "8  test_00008             0\n",
      "9  test_00009             1\n",
      "\n",
      "Submission shape: (32439, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'final_status': test_predictions\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission.to_csv('baseline_rf_submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created: baseline_rf_submission.csv\")\n",
    "print(\"\\nSubmission preview:\")\n",
    "print(submission.head(10))\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "BASELINE RANDOM FOREST MODEL SUMMARY\n",
      "==================================================\n",
      "\n",
      "ðŸ“Š PERFORMANCE METRICS:\n",
      "   Training F1 Score: 0.7251\n",
      "   Validation F1 Score: 0.5234\n",
      "   Final Training F1 Score: 0.7113\n",
      "\n",
      "ðŸ”§ MODEL CONFIGURATION:\n",
      "   Algorithm: Random Forest\n",
      "   Number of trees: 100\n",
      "   Max depth: 15\n",
      "   Class weight: balanced\n",
      "   Features used: 17\n",
      "\n",
      "ðŸ“ˆ TOP 3 IMPORTANT FEATURES:\n",
      "   1. prep_time: 13.20%\n",
      "   2. goal_per_day: 9.80%\n",
      "   3. log_goal: 9.23%\n",
      "\n",
      "ðŸ“‹ PREDICTIONS:\n",
      "   Test set size: 32439\n",
      "   Predicted successes: 14015 (43.2%)\n",
      "   Submission file: baseline_rf_submission.csv\n",
      "\n",
      "ðŸ’¡ BASELINE ESTABLISHED!\n",
      "   Validation F1 Score: 0.5234\n",
      "   This serves as the benchmark for model improvements.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BASELINE RANDOM FOREST MODEL SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nðŸ“Š PERFORMANCE METRICS:\")\n",
    "print(f\"   Training F1 Score: {train_f1:.4f}\")\n",
    "print(f\"   Validation F1 Score: {val_f1:.4f}\")\n",
    "print(f\"   Final Training F1 Score: {train_final_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ”§ MODEL CONFIGURATION:\")\n",
    "print(f\"   Algorithm: Random Forest\")\n",
    "print(f\"   Number of trees: 100\")\n",
    "print(f\"   Max depth: 15\")\n",
    "print(f\"   Class weight: balanced\")\n",
    "print(f\"   Features used: {len(feature_cols)}\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ TOP 3 IMPORTANT FEATURES:\")\n",
    "for i, (_, row) in enumerate(feature_importance.head(3).iterrows()):\n",
    "    print(f\"   {i+1}. {row['feature']}: {row['importance']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ PREDICTIONS:\")\n",
    "print(f\"   Test set size: {len(test_predictions)}\")\n",
    "print(f\"   Predicted successes: {sum(test_predictions)} ({sum(test_predictions)/len(test_predictions)*100:.1f}%)\")\n",
    "print(f\"   Submission file: baseline_rf_submission.csv\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ BASELINE ESTABLISHED!\")\n",
    "print(f\"   Validation F1 Score: {val_f1:.4f}\")\n",
    "print(f\"   This serves as the benchmark for model improvements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
